{"authors": ["Parmy Olsen"], "date_download": "2024-10-12 13:27:22", "date_modify": "2024-10-12 13:27:22", "date_publish": "2023-12-04 17:00:00", "description": "The hype around Q* has boosted excitement about the company’s engineering prowess. Read more at straitstimes.com.", "filename": "opinion_openai-s-q-is-alarming-for-a-different-reason_1728739642.html", "image_url": "https://static1.straitstimes.com.sg/s3fs-public/styles/large30x20/public/articles/2023/12/04/2023-11-30T010556Z540926341RC2CN4AWM9NJRTRMADP3OPENAI-BOARD-MICROSOFT.JPG", "language": "en", "localpath": "/Users/bryansoong/news-please-repo//data/2024/10/12/straitstimes.com/opinion_openai-s-q-is-alarming-for-a-different-reason_1728739642.html", "title": "OpenAI’s Q* is alarming for a different reason", "title_page": "OpenAI’s Q* is alarming for a different reason | The Straits Times", "title_rss": "NULL", "source_domain": "straitstimes.com", "maintext": "When news stories emerged last week that OpenAI had been working on a new AI model called Q* (pronounced “Q star”), some suggested this was a major step towards powerful, human-like artificial intelligence that could one day go rogue. What’s more certain: The hype around Q* has boosted excitement about the company’s engineering prowess, just as it’s steadying itself from a failed board coup.\nPeaks of AI excitement about milestones have taken the public for a ride plenty of times before. The real warning we should take from Q* is the direction in which these systems are progressing. As they get better at reasoning, it will become more tempting to give such tools greater responsibilities. More than any concerns about AI annihilation, that alone should give us pause.", "url": "https://www.straitstimes.com/opinion/openai-s-q-is-alarming-for-a-different-reason"}