{"authors": ["Marietje Schaake"], "date_download": "2024-10-12 13:36:55", "date_modify": "2024-10-12 13:36:55", "date_publish": "2024-04-30 17:00:00", "description": "Government attempts to regulate the technology must look at its use on the battlefield. Read more at straitstimes.com.", "filename": "opinion_military-is-the-missing-word-in-ai-safety-discussions_1728740215.html", "image_url": "https://static1.straitstimes.com.sg/s3fs-public/styles/large30x20/public/articles/2024/04/30/11297702.jpg?VersionId=F4eNfIHH3OUzjNX6V5TG91W1gG5s0TsC", "language": "en", "localpath": "/Users/bryansoong/news-please-repo//data/2024/10/12/straitstimes.com/opinion_military-is-the-missing-word-in-ai-safety-discussions_1728740215.html", "title": "Military is the missing word in AI safety discussions", "title_page": "Military is the missing word in AI safety discussions | The Straits Times", "title_rss": "NULL", "source_domain": "straitstimes.com", "maintext": "Western governments are racing each other to set up artificial intelligence (AI) safety institutes. The UK, US, Japan and Canada have all announced such initiatives, while the US Department of Homeland Security added an AI Safety and Security Board to the mix only last week. Given this heavy emphasis on safety, it is remarkable that none of these bodies governs the military use of AI. Meanwhile, the modern-day battlefield is already demonstrating the potential for clear AI safety risks.\nAccording to a recent investigation by the Israeli magazine +972, the Israel Defence Forces have used an AI-enabled program called Lavender to flag targets for drone attacks. The system combines data and intelligence sources to identify suspected militants. The program allegedly identified tens of thousands of targets, and bombs dropped in Gaza resulted in excessive collateral deaths and damage. The IDF denies several aspects of the report.", "url": "https://www.straitstimes.com/opinion/military-is-the-missing-word-in-ai-safety-discussions"}